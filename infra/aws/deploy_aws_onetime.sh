#!/bin/bash
set -e

# Parse command line arguments
QUICK_MODE=false
LAMBDA_ONLY=false
FRONTEND_ONLY=false

while [[ $# -gt 0 ]]; do
    case $1 in
        --quick)
            QUICK_MODE=true
            shift
            ;;
        --lambda-only)
            LAMBDA_ONLY=true
            shift
            ;;
        --frontend-only)
            FRONTEND_ONLY=true
            shift
            ;;
        *)
            echo "Unknown option: $1"
            echo "Usage: $0 [--quick] [--lambda-only] [--frontend-only]"
            exit 1
            ;;
    esac
done

echo "üöÄ Deploying 7H Stock Analyzer to AWS (Cost-Optimized)..."
if [ "$QUICK_MODE" = true ]; then
    echo "‚ö° Quick mode enabled - Lambda-only update"
fi

# Load environment variables
if [ ! -f .env.local ]; then
    echo "‚ùå .env.local not found. Please create .env.local with AWS configuration."
    exit 1
fi

export $(grep -v '^#' .env.local | xargs)

# Check if AWS CLI is configured
if ! aws sts get-caller-identity &>/dev/null; then
    echo "‚ùå AWS CLI not configured. Please run 'aws configure' first."
    exit 1
fi

# Get AWS account info
AWS_ACCOUNT=$(aws sts get-caller-identity --query Account --output text)
AWS_REGION=${AWS_REGION:-us-east-1}

echo "üìã Deployment Configuration:"
echo "  Account: $AWS_ACCOUNT"
echo "  Region: $AWS_REGION"
echo "  Environment: ${ENVIRONMENT:-dev}"

# Set environment-specific variables
ENVIRONMENT=${ENVIRONMENT:-production}
STACK_NAME="7h-stock-analyzer-${ENVIRONMENT}"

# Quick mode: Skip infrastructure setup and directly update Lambda
if [ "$QUICK_MODE" = true ]; then
    echo "‚ö° Quick Lambda Update Mode"
    echo "  Skipping infrastructure setup..."
    echo "  Updating Lambda function code directly..."
    
    # Get existing Lambda function name from stack
    LAMBDA_FUNCTION_NAME=$(aws lambda list-functions \
        --query "Functions[?contains(FunctionName, 'StockAnalyzerFunction')].FunctionName" \
        --output text \
        --region $AWS_REGION)
    
    if [ -z "$LAMBDA_FUNCTION_NAME" ] || [ "$LAMBDA_FUNCTION_NAME" = "None" ]; then
        echo "‚ùå Lambda function not found. Please run full deployment first."
        exit 1
    fi
    
    echo "üîß Found Lambda function: $LAMBDA_FUNCTION_NAME"
    
    # Build application package (quick version)
    echo "üì¶ Building application package..."
    rm -rf ../build/package
    mkdir -p ../build/package
    
    # Copy only necessary files
    cp -r /Users/sriramrajendran/7_projects/7h-stock-analyzer/backend/app ../build/package/
    cp /Users/sriramrajendran/7_projects/7h-stock-analyzer/backend/requirements.txt ../build/package/
    
    # Create zip
    cd ../build/package
    zip -r ../../stock-analyzer-lambda-quick.zip . -x "*.pyc" "*.pyo" "__pycache__/*"
    cd ../..
    
    PACKAGE_SIZE=$(du -h stock-analyzer-lambda-quick.zip | cut -f1)
    echo "‚úÖ Application package created: $PACKAGE_SIZE"
    
    # Update Lambda function code directly
    echo "üîÑ Updating Lambda function code..."
    aws lambda update-function-code \
        --function-name "$LAMBDA_FUNCTION_NAME" \
        --zip-file fileb://stock-analyzer-lambda-quick.zip \
        --region $AWS_REGION
    
    # Wait for update to complete
    echo "‚è≥ Waiting for Lambda update to complete..."
    aws lambda wait function-updated \
        --function-name "$LAMBDA_FUNCTION_NAME" \
        --region $AWS_REGION
    
    # Update Lambda environment variables with all credentials from .env.local
    echo "ÔøΩ Updating Lambda environment variables from .env.local..."
    
    # Build environment variables JSON with all available variables
    ENV_VARS=$(cat <<EOF
{
    "Variables": {
        "API_KEY": "$API_KEY",
        "ENVIRONMENT": "${ENVIRONMENT:-production}",
        "APP_AWS_REGION": "$AWS_REGION",
        "S3_BUCKET_NAME": "$S3_BUCKET_NAME_PROD",
        "LOG_LEVEL": "${LOG_LEVEL:-INFO}",
        "PUSHOVER_TOKEN": "$PUSHOVER_TOKEN",
        "PUSHOVER_USER": "$PUSHOVER_USER",
        "REQUIRE_AUTH": "${REQUIRE_AUTH:-true}",
        "ENABLE_NOTIFICATIONS": "${ENABLE_NOTIFICATIONS:-false}"
    }
}
EOF
)
    
    # Update Lambda configuration
    aws lambda update-function-configuration \
        --function-name "$LAMBDA_FUNCTION_NAME" \
        --environment "$ENV_VARS" \
        --region $AWS_REGION
    
    echo "‚úÖ Lambda environment variables updated with all .env.local credentials"
    echo "  - API_KEY: ‚úì"
    echo "  - ENVIRONMENT: $ENVIRONMENT"
    echo "  - AWS_REGION: $AWS_REGION"
    echo "  - S3_BUCKET_NAME: $S3_BUCKET_NAME_PROD"
    echo "  - LOG_LEVEL: $LOG_LEVEL"
    echo "  - PUSHOVER_TOKEN: ‚úì"
    echo "  - PUSHOVER_USER: ‚úì"
    echo "  - REQUIRE_AUTH: $REQUIRE_AUTH"
    echo "  - ENABLE_NOTIFICATIONS: $ENABLE_NOTIFICATIONS"
    
    # Test the updated function
    echo "üß™ Testing updated Lambda function..."
    API_URL=$(aws cloudformation describe-stacks \
        --stack-name stock-analyzer-prod \
        --region $AWS_REGION \
        --query 'Stacks[0].Outputs[?OutputKey==`StockAnalyzerApi`].OutputValue' \
        --output text)
    
    if [ -n "$API_URL" ] && [ "$API_URL" != "None" ]; then
        echo "üåê Testing API endpoint: $API_URL/health"
        HEALTH_RESPONSE=$(curl -s -w "%{http_code}" "$API_URL/health" || echo "000")
        
        if [[ "$HEALTH_RESPONSE" == *"200"* ]]; then
            echo "‚úÖ Lambda function updated and tested successfully"
        else
            echo "‚ö†Ô∏è  Lambda updated but health check failed: $HEALTH_RESPONSE"
        fi
    else
        echo "‚ö†Ô∏è  Could not get API URL for testing"
    fi
    
    # Clean up
    rm -f stock-analyzer-lambda-quick.zip
    rm -rf ../build/package
    
    echo ""
    echo "üéâ Quick Lambda deployment completed!"
    echo "‚ö° Deployment time: ~30-60 seconds (vs 15+ minutes for full deployment)"
    echo ""
    echo "üìã Quick deployment info:"
    echo "  Function: $LAMBDA_FUNCTION_NAME"
    echo "  API URL: $API_URL"
    echo "  Package size: $PACKAGE_SIZE"
    echo ""
    echo "üí° For full infrastructure changes, run without --quick flag"
    
    exit 0
fi

# Cost optimization settings
MEMORY_SIZE=${MEMORY_SIZE:-512}  # Reduced from 1024MB
TIMEOUT=${TIMEOUT:-180}  # Reduced from 300s
RESERVED_CONCURRENCY=${RESERVED_CONCURRENCY:-2}  # Reduced from 5

echo "üí∞ Cost Optimization Settings:"
echo "  Memory: ${MEMORY_SIZE}MB"
echo "  Timeout: ${TIMEOUT}s"
echo "  Concurrency: ${RESERVED_CONCURRENCY}"

# Create S3 bucket for deployment artifacts
DEPLOYMENT_BUCKET="$S3_BUCKET_NAME_PROD"
echo "ü™£ Creating deployment bucket: $DEPLOYMENT_BUCKET"

if ! aws s3 ls "s3://$DEPLOYMENT_BUCKET" &>/dev/null; then
    aws s3 mb "s3://$DEPLOYMENT_BUCKET" --region $AWS_REGION
    echo "‚úÖ Created deployment bucket"
else
    echo "‚ÑπÔ∏è  Deployment bucket already exists"
fi

# Build Lambda layer
echo "üì¶ Building Lambda layer..."

# Create build directories
echo "üèóÔ∏è Creating build directories..."
mkdir -p ../build/layer/python
mkdir -p ../build/package

# Install production dependencies with Lambda compatibility
echo "Installing production dependencies with Lambda-compatible wheels..."
# Install numpy and pandas with manylinux wheels for Lambda compatibility
pip install \
    --platform manylinux2014_x86_64 \
    --only-binary=:all: \
    --target ../build/layer/python \
    numpy==2.2.6 \
    pandas==2.2.3 \
    yfinance==0.2.28

# Install remaining dependencies
pip install \
    --target ../build/layer/python \
    fastapi==0.65.0 \
    mangum==0.17.0 \
    uvicorn==0.15.0 \
    boto3==1.36.0 \
    botocore==1.36.0 \
    requests==2.31.0 \
    python-dateutil==2.8.2 \
    pytz==2023.3 \
    urllib3==2.2.2 \
    six==1.16.0 \
    certifi==2024.2.2

# Optimize layer size
echo "Optimizing layer size..."
find ../build/layer/python -type d -name "__pycache__" -exec rm -rf {} + 2>/dev/null || true
find ../build/layer/python -name "*.pyc" -delete 2>/dev/null || true
find ../build/layer/python -name "*.pyo" -delete 2>/dev/null || true
find ../build/layer/python -name "*.pyd" -delete 2>/dev/null || true
find ../build/layer/python -name "*.so" -delete 2>/dev/null || true

# Remove unnecessary files
rm -rf ../build/layer/python/*/tests 2>/dev/null || true
rm -rf ../build/layer/python/*/.github 2>/dev/null || true
rm -rf ../build/layer/python/*/doc 2>/dev/null || true

# Compress layer
echo "Compressing layer..."
cd ../build/layer
zip -r ../../stock-analyzer-layer.zip python -x "*.pyc" "*.pyo" "__pycache__/*"
cd ../../..

LAYER_SIZE=$(du -h stock-analyzer-layer.zip | cut -f1)
echo "‚úÖ Lambda layer created: $LAYER_SIZE"

# Build application package
echo "üì¶ Building application package..."
rm -rf ../build/package
mkdir -p ../build/package

# Copy only necessary files
cp -r /Users/sriramrajendran/7_projects/7h-stock-analyzer/backend/app ../build/package/
cp /Users/sriramrajendran/7_projects/7h-stock-analyzer/backend/requirements.txt ../build/package/

# Create zip
cd ../build/package
zip -r ../../stock-analyzer-lambda.zip . -x "*.pyc" "*.pyo" "__pycache__/*"
cd ../../..

PACKAGE_SIZE=$(du -h stock-analyzer-lambda.zip | cut -f1)
echo "‚úÖ Application package created: $PACKAGE_SIZE"

# Upload to S3
echo "üì§ Uploading to S3..."
aws s3 cp stock-analyzer-layer.zip "s3://$DEPLOYMENT_BUCKET/"
aws s3 cp stock-analyzer-lambda.zip "s3://$DEPLOYMENT_BUCKET/"

# Deploy with SAM (cost-optimized template)
echo "üöÄ Deploying with SAM..."
sam deploy \
    --template-file template.yaml \
    --stack-name stock-analyzer-prod \
    --region $AWS_REGION \
    --s3-bucket $DEPLOYMENT_BUCKET \
    --parameter-overrides \
        Environment=production \
    --capabilities CAPABILITY_IAM CAPABILITY_NAMED_IAM CAPABILITY_AUTO_EXPAND \
    --no-confirm-changeset \
    --no-fail-on-empty-changeset

# Get stack outputs
echo "üìã Getting stack outputs..."
API_URL=$(aws cloudformation describe-stacks \
    --stack-name stock-analyzer-prod \
    --region $AWS_REGION \
    --query 'Stacks[0].Outputs[?OutputKey==`StockAnalyzerApi`].OutputValue' \
    --output text)

S3_BUCKET=$(aws cloudformation describe-stacks \
    --stack-name stock-analyzer-prod \
    --region $AWS_REGION \
    --query 'Stacks[0].Outputs[?OutputKey==`StockDataBucket`].OutputValue' \
    --output text)

LAMBDA_ARN=$(aws cloudformation describe-stacks \
    --stack-name stock-analyzer-prod \
    --region $AWS_REGION \
    --query 'Stacks[0].Outputs[?OutputKey==`StockAnalyzerFunction`].OutputValue' \
    --output text)

API_KEY=$(aws cloudformation describe-stacks \
    --stack-name stock-analyzer-prod \
    --region $AWS_REGION \
    --query 'Stacks[0].Outputs[?OutputKey==`StockAnalyzerApiKey`].OutputValue' \
    --output text)

# Store API key in SSM Parameter Store (secure, not hardcoded)
echo "üîê Storing API key in SSM Parameter Store..."
if [ -z "$API_KEY" ]; then
    echo "‚ùå API_KEY not found in environment variables"
    echo "Please set API_KEY in your .env.local file"
    exit 1
fi

aws ssm put-parameter \
    --name "/stock-analyzer/api-key" \
    --value "$API_KEY" \
    --type "SecureString" \
    --description "Stock Analyzer API Key" \
    --overwrite

# Configure Lambda environment variables with all credentials from .env.local
echo "ÔøΩ Configuring Lambda environment variables from .env.local..."

# Get Lambda function name from stack outputs
LAMBDA_FUNCTION_NAME=$(aws cloudformation describe-stacks \
    --stack-name stock-analyzer-prod \
    --region $AWS_REGION \
    --query 'Stacks[0].Outputs[?OutputKey==`StockAnalyzerFunction`].OutputValue' \
    --output text)

if [ -n "$LAMBDA_FUNCTION_NAME" ] && [ "$LAMBDA_FUNCTION_NAME" != "None" ]; then
    # Extract function name from ARN
    LAMBDA_SHORT_NAME=$(basename "$LAMBDA_FUNCTION_NAME")
    
    echo "üîß Updating Lambda environment variables for: $LAMBDA_SHORT_NAME"
    
    # Build environment variables JSON with all available variables
    ENV_VARS=$(cat <<EOF
{
    "Variables": {
        "API_KEY": "$API_KEY",
        "ENVIRONMENT": "${ENVIRONMENT:-production}",
        "APP_AWS_REGION": "$AWS_REGION",
        "S3_BUCKET_NAME": "$S3_BUCKET_NAME_PROD",
        "LOG_LEVEL": "${LOG_LEVEL:-INFO}",
        "PUSHOVER_TOKEN": "$PUSHOVER_TOKEN",
        "PUSHOVER_USER": "$PUSHOVER_USER",
        "REQUIRE_AUTH": "${REQUIRE_AUTH:-true}",
        "ENABLE_NOTIFICATIONS": "${ENABLE_NOTIFICATIONS:-false}"
    }
}
EOF
)
    
    # Update Lambda configuration
    aws lambda update-function-configuration \
        --function-name "$LAMBDA_SHORT_NAME" \
        --environment "$ENV_VARS" \
        --region $AWS_REGION
    
    echo "‚úÖ Lambda environment variables updated with all .env.local credentials"
    echo "  - API_KEY: ‚úì"
    echo "  - ENVIRONMENT: $ENVIRONMENT"
    echo "  - AWS_REGION: $AWS_REGION"
    echo "  - S3_BUCKET_NAME: $S3_BUCKET_NAME_PROD"
    echo "  - LOG_LEVEL: $LOG_LEVEL"
    echo "  - PUSHOVER_TOKEN: ‚úì"
    echo "  - PUSHOVER_USER: ‚úì"
    echo "  - REQUIRE_AUTH: $REQUIRE_AUTH"
    echo "  - ENABLE_NOTIFICATIONS: $ENABLE_NOTIFICATIONS"
else
    echo "‚ö†Ô∏è  Could not find Lambda function name - skipping environment variable update"
fi

# Set up CloudWatch billing alerts
echo "üí∞ Setting up CloudWatch billing alerts..."
SNS_TOPIC_ARN=$(aws sns create-topic --name "stock-analyzer-billing-alerts" --query "TopicArn" --output text)

aws cloudwatch put-metric-alarm \
    --alarm-name "Stock-Analyzer-High-Cost" \
    --alarm-description "Alert when monthly costs exceed $10" \
    --metric-name "EstimatedCharges" \
    --namespace "AWS/Billing" \
    --statistic "Maximum" \
    --period 21600 \
    --evaluation-periods 1 \
    --threshold 10 \
    --comparison-operator "GreaterThanThreshold" \
    --unit "USD" \
    --alarm-actions "$SNS_TOPIC_ARN"

echo "‚úÖ CloudWatch billing alarm created with $10 threshold"

echo ""
echo "üéâ Deployment completed successfully!"
echo ""
echo "üìã Stack Information:"
echo "  Stack Name: $STACK_NAME"
echo "  API URL: $API_URL"
echo "  S3 Bucket: $S3_BUCKET"
echo "  Lambda ARN: $LAMBDA_ARN"
echo "  API Key: $API_KEY"
echo "  CloudFront: https://d224ztwcw6zi6e.cloudfront.net"
echo "  Billing Alert: $10 threshold configured"
echo "  Rate Limiting: Route-specific throttling enabled"
echo ""
echo "üß™ Test the deployment:"
echo "  curl -H \"X-API-Key: \$API_KEY\" $API_URL/health"
echo "  curl -H \"X-API-Key: \$API_KEY\" $API_URL/recommendations"
echo "  curl -H \"X-API-Key: \$API_KEY\" $API_URL/history/2024-02-07"
echo ""
echo "üåê Frontend URLs:"
echo "  HTTPS CDN: https://d224ztwcw6zi6e.cloudfront.net"
echo "  S3 Direct: http://7h-stock-analyzer.s3-website-us-east-1.amazonaws.com"
echo ""
echo "üí∞ Cost Optimization Applied:"
echo "  ‚úÖ Reduced memory to ${MEMORY_SIZE}MB"
echo "  ‚úÖ Reduced timeout to ${TIMEOUT}s"
echo "  ‚úÖ Limited concurrency to ${RESERVED_CONCURRENCY}"
echo "  ‚úÖ Disabled VPC (reduces cost)"
echo "  ‚úÖ Optimized layer size ($LAYER_SIZE)"
echo "  ‚úÖ Rate limiting configured (HTTP API - FREE)"
echo ""
echo "üìä Estimated Monthly Cost: < $15"
echo "  - Lambda: ~$8 (based on 100k invocations/month)"
echo "  - S3: ~$3 (storage + requests)"
echo "  - API Gateway: ~$4 (1M requests/month)"
echo "  - Rate Limiting: $0.00 (HTTP API throttling included)"
echo "  - CloudWatch Logs: ~$0.50 (log ingestion)"
echo "  - CloudWatch Alarms: ~$0.10 (billing alerts)"
echo "  - CloudFront: ~$0.00 (free tier: 1TB + 10M requests)"
echo "  - Total: ~$15.60/month (conservative high-usage estimate)"
echo "  - Light usage: ~$2.46/month (61 invocations/month)"

# Clean up local files
echo "üßπ Cleaning up local files..."
rm -f stock-analyzer-layer.zip stock-analyzer-lambda.zip
rm -rf ../build

# =============================================================================
# INFRASTRUCTURE AS CODE - CONSOLIDATED FUNCTIONS
# =============================================================================

# Function to cleanup old CloudFront distributions (from cleanup_cloudfront.sh)
cleanup_old_cloudfront_distributions() {
    echo "üßπ Cleaning up old CloudFront distributions..."
    
    # Get all distributions with the bucket comment
    local bucket_name="$S3_BUCKET_NAME_PROD"
    local old_distributions=$(aws cloudfront list-distributions \
        --query "DistributionList.Items[?Comment=='$bucket_name frontend'].Id" \
        --output text 2>/dev/null || echo "")
    
    if [ -n "$old_distributions" ] && [ "$old_distributions" != "None" ]; then
        echo "Found old distributions: $old_distributions"
        
        for dist_id in $old_distributions; do
            echo "üóëÔ∏è  Deleting old distribution: $dist_id"
            
            # Get ETag for the distribution
            local etag=$(aws cloudfront get-distribution --id $dist_id --query 'ETag' --output text 2>/dev/null || echo "")
            
            if [ -n "$etag" ]; then
                # First disable the distribution
                echo "  Disabling distribution..."
                aws cloudfront update-distribution \
                    --id $dist_id \
                    --distribution-config '{
                        "CallerReference": "'$dist_id'-cleanup",
                        "Comment": "'$bucket_name frontend - marked for deletion",
                        "DefaultRootObject": "index.html",
                        "Origins": {
                            "Quantity": 1,
                            "Items": [{
                                "Id": "S3-'$bucket_name'",
                                "DomainName": "'$bucket_name'.s3.'$AWS_REGION'.amazonaws.com",
                                "S3OriginConfig": {
                                    "OriginAccessIdentity": ""
                                }
                            }]
                        },
                        "DefaultCacheBehavior": {
                            "TargetOriginId": "S3-'$bucket_name'",
                            "ViewerProtocolPolicy": "redirect-to-https",
                            "ForwardedValues": {
                                "QueryString": false,
                                "Cookies": {
                                    "Forward": "none"
                                }
                            },
                            "MinTTL": 3600,
                            "DefaultTTL": 86400,
                            "MaxTTL": 31536000
                        },
                        "CacheBehaviors": {
                            "Quantity": 0
                        },
                        "Enabled": false,
                        "PriceClass": "PriceClass_100"
                    }' \
                    --if-match "$etag" 2>/dev/null || echo "  Failed to disable distribution"
                
                # Wait for distribution to be disabled
                echo "  Waiting for distribution to be disabled..."
                aws cloudfront wait distribution-deployed --id $dist_id 2>/dev/null || echo "  Timeout waiting for disable"
                
                # Delete the distribution
                echo "  Deleting distribution..."
                etag=$(aws cloudfront get-distribution --id $dist_id --query 'ETag' --output text 2>/dev/null || echo "")
                if [ -n "$etag" ]; then
                    aws cloudfront delete-distribution --id $dist_id --if-match "$etag" 2>/dev/null || echo "  Failed to delete distribution"
                fi
            fi
        done
        
        echo "‚úÖ CloudFront cleanup completed"
    else
        echo "‚ÑπÔ∏è  No old distributions found to cleanup"
    fi
}

# Function to monitor costs (from monitor_costs.sh)
monitor_costs() {
    echo "üí∞ AWS Cost Monitoring for 7H Stock Analyzer..."
    
    # Get service costs
    local lambda_cost=$(aws ce get-cost-and-usage \
        --time-period Start=$(date -d "30 days ago" +%Y-%m-%d),End=$(date +%Y-%m-%d) \
        --filter Dimensions={Key=SERVICE,Values=["AWS Lambda"]} \
        --metrics BlendedCost \
        --granularity MONTHLY \
        --query 'ResultsByTime[0].Total.BlendedCost.Amount' \
        --output text 2>/dev/null || echo "0")
    
    local s3_cost=$(aws ce get-cost-and-usage \
        --time-period Start=$(date -d "30 days ago" +%Y-%m-%d),End=$(date +%Y-%m-%d) \
        --filter Dimensions={Key=SERVICE,Values=["Amazon S3"]} \
        --metrics BlendedCost \
        --granularity MONTHLY \
        --query 'ResultsByTime[0].Total.BlendedCost.Amount' \
        --output text 2>/dev/null || echo "0")
    
    local api_cost=$(aws ce get-cost-and-usage \
        --time-period Start=$(date -d "30 days ago" +%Y-%m-%d),End=$(date +%Y-%m-%d) \
        --filter Dimensions={Key=SERVICE,Values=["Amazon API Gateway"]} \
        --metrics BlendedCost \
        --granularity MONTHLY \
        --query 'ResultsByTime[0].Total.BlendedCost.Amount' \
        --output text 2>/dev/null || echo "0")
    
    echo "üìà Cost Analysis (Last 30 Days)"
    echo "================================"
    echo "üîß Lambda Service: $${lambda_cost}"
    echo "ü™£ S3 Service: $${s3_cost}"
    echo "üåê API Gateway: $${api_cost}"
    
    local total_cost=$(aws ce get-cost-and-usage \
        --time-period Start=$(date -d "30 days ago" +%Y-%m-%d),End=$(date +%Y-%m-%d) \
        --filter Dimensions={Key=SERVICE,Values=["AWS Lambda","Amazon S3","Amazon API Gateway","Amazon CloudWatch"]} \
        --metrics BlendedCost \
        --granularity MONTHLY \
        --query 'ResultsByTime[0].Total.BlendedCost.Amount' \
        --output text 2>/dev/null || echo "0")
    
    echo "üí∏ Total (30 days): $${total_cost}"
    
    if (( $(echo "$total_cost > 20" | bc -l) )); then
        echo "  ‚ö†Ô∏è  Cost is above $20 - consider optimization"
    elif (( $(echo "$total_cost > 10" | bc -l) )); then
        echo "  ‚úÖ Cost is moderate - monitor usage"
    else
        echo "  ‚úÖ Cost is well optimized"
    fi
}

# Function to sync with production infrastructure
sync_production_infra() {
    echo "üîÑ Production Infrastructure Sync Check"
    echo "===================================="
    
    local sync_issues=0
    local stack_name="stock-analyzer-prod"
    
    echo "üìã Checking CloudFormation stack sync..."
    
    # Check if stack exists
    if ! aws cloudformation describe-stacks --stack-name "$stack_name" &>/dev/null; then
        echo "‚ùå Stack '$stack_name' not found in production"
        echo "   Run full deployment first: $0"
        sync_issues=$((sync_issues + 1))
        return 1
    fi
    
    echo "‚úÖ Stack '$stack_name' found"
    
    # Get stack outputs
    local api_url=$(aws cloudformation describe-stacks \
        --stack-name "$stack_name" \
        --query 'Stacks[0].Outputs[?OutputKey==`StockAnalyzerApi`].OutputValue' \
        --output text 2>/dev/null || echo "")
    
    local s3_bucket=$(aws cloudformation describe-stacks \
        --stack-name "$stack_name" \
        --query 'Stacks[0].Outputs[?OutputKey==`StockDataBucket`].OutputValue' \
        --output text 2>/dev/null || echo "")
    
    local lambda_arn=$(aws cloudformation describe-stacks \
        --stack-name "$stack_name" \
        --query 'Stacks[0].Outputs[?OutputKey==`StockAnalyzerFunction`].OutputValue' \
        --output text 2>/dev/null || echo "")
    
    echo ""
    echo "üîß Lambda Configuration Sync:"
    
    # Check Lambda function configuration
    if [ -n "$lambda_arn" ]; then
        local lambda_name=$(basename "$lambda_arn")
        
        # Get current Lambda config
        local current_memory=$(aws lambda get-function-configuration \
            --function-name "$lambda_name" \
            --query 'MemorySize' \
            --output text 2>/dev/null || echo "")
        
        local current_timeout=$(aws lambda get-function-configuration \
            --function-name "$lambda_name" \
            --query 'Timeout' \
            --output text 2>/dev/null || echo "")
        
        local current_runtime=$(aws lambda get-function-configuration \
            --function-name "$lambda_name" \
            --query 'Runtime' \
            --output text 2>/dev/null || echo "")
        
        # Expected values from script
        local expected_memory="512"
        local expected_timeout="180" 
        local expected_runtime="python3.10"
        
        echo "  Function: $lambda_name"
        echo "  Memory: ${current_memory}MB (expected: ${expected_memory}MB)"
        echo "  Timeout: ${current_timeout}s (expected: ${expected_timeout}s)"
        echo "  Runtime: $current_runtime (expected: $expected_runtime)"
        
        # Check for mismatches
        if [ "$current_memory" != "$expected_memory" ]; then
            echo "  ‚ùå Memory mismatch - Update needed"
            sync_issues=$((sync_issues + 1))
        else
            echo "  ‚úÖ Memory synced"
        fi
        
        if [ "$current_timeout" != "$expected_timeout" ]; then
            echo "  ‚ùå Timeout mismatch - Update needed"
            sync_issues=$((sync_issues + 1))
        else
            echo "  ‚úÖ Timeout synced"
        fi
        
        if [ "$current_runtime" != "$expected_runtime" ]; then
            echo "  ‚ùå Runtime mismatch - Update needed"
            sync_issues=$((sync_issues + 1))
        else
            echo "  ‚úÖ Runtime synced"
        fi
    else
        echo "  ‚ùå Lambda function not found"
        sync_issues=$((sync_issues + 1))
    fi
    
    echo ""
    echo "üåê API Gateway Configuration Sync:"
    
    # Check API Gateway
    if [ -n "$api_url" ]; then
        echo "  API URL: $api_url"
        
        # Extract API ID from URL
        local api_id=$(echo "$api_url" | sed 's|https://||' | sed 's|\.execute-api.*||')
        
        if [ -n "$api_id" ]; then
            # Get API Gateway stage configuration
            local stage_config=$(aws apigatewayv2 get-stage \
                --api-id "$api_id" \
                --stage-name "\$default" \
                --query 'RouteSettings' \
                --output json 2>/dev/null || echo "{}")
            
            echo "  ‚úÖ API Gateway found: $api_id"
            
            # Check key routes
            local key_routes=("/run-now" "/recon/run" "/config/update" "/analysis/{symbol}")
            
            for route in "${key_routes[@]}"; do
                local route_config=$(echo "$stage_config" | jq -r ".[\"$route\"] // empty" 2>/dev/null)
                if [ -n "$route_config" ]; then
                    echo "    ‚úÖ Route $route: Configured"
                else
                    echo "    ‚ùå Route $route: Missing"
                    sync_issues=$((sync_issues + 1))
                fi
            done
        fi
    else
        echo "  ‚ùå API Gateway not found"
        sync_issues=$((sync_issues + 1))
    fi
    
    echo ""
    echo "ü™£ S3 Configuration Sync:"
    
    # Check S3 bucket
    if [ -n "$s3_bucket" ]; then
        echo "  Bucket: $s3_bucket"
        
        # Check if bucket exists
        if aws s3 ls "s3://$s3_bucket" &>/dev/null; then
            echo "  ‚úÖ Bucket exists"
            
            # Check bucket versioning
            local versioning=$(aws s3api get-bucket-versioning \
                --bucket "$s3_bucket" \
                --query 'Status' \
                --output text 2>/dev/null || echo "Disabled")
            
            echo "  Versioning: $versioning"
            
            # Check bucket encryption
            local encryption=$(aws s3api get-bucket-encryption \
                --bucket "$s3_bucket" \
                --query 'ServerSideEncryptionConfiguration.Rules[0].ApplyServerSideEncryptionByDefault.SSEAlgorithm' \
                --output text 2>/dev/null || echo "None")
            
            echo "  Encryption: $encryption"
            
            # Check for required prefixes
            local prefixes=("data/" "recon/" "config/")
            for prefix in "${prefixes[@]}"; do
                if aws s3 ls "s3://$s3_bucket/$prefix" &>/dev/null; then
                    echo "    ‚úÖ Prefix $prefix exists"
                else
                    echo "    ‚ö†Ô∏è  Prefix $prefix missing (will be created on first use)"
                fi
            done
        else
            echo "  ‚ùå Bucket not accessible"
            sync_issues=$((sync_issues + 1))
        fi
    else
        echo "  ‚ùå S3 bucket not found"
        sync_issues=$((sync_issues + 1))
    fi
    
    echo ""
    echo "üåê CloudFront Configuration Sync:"
    
    # Check CloudFront distribution
    local distribution_id=$(aws cloudfront list-distributions \
        --query "DistributionList.Items[?Comment=='$S3_BUCKET_NAME_PROD frontend'].Id" \
        --output text 2>/dev/null || echo "")
    
    if [ -n "$distribution_id" ] && [ "$distribution_id" != "None" ]; then
        echo "  Distribution ID: $distribution_id"
        
        local distribution_status=$(aws cloudfront get-distribution \
            --id "$distribution_id" \
            --query 'Distribution.Status' \
            --output text 2>/dev/null || echo "")
        
        local distribution_domain=$(aws cloudfront get-distribution \
            --id "$distribution_id" \
            --query 'Distribution.DomainName' \
            --output text 2>/dev/null || echo "")
        
        echo "  Status: $distribution_status"
        echo "  Domain: $distribution_domain"
        
        if [ "$distribution_status" = "Deployed" ]; then
            echo "  ‚úÖ CloudFront deployed"
        else
            echo "  ‚ö†Ô∏è  CloudFront not fully deployed"
        fi
    else
        echo "  ‚ùå CloudFront distribution not found"
        sync_issues=$((sync_issues + 1))
    fi
    
    echo ""
    echo "üîê Security Configuration Sync:"
    
    # Check SSM Parameter Store for API key
    local api_key_param=$(aws ssm get-parameter \
        --name "/stock-analyzer/api-key" \
        --with-decryption \
        --query 'Parameter.Value' \
        --output text 2>/dev/null || echo "")
    
    if [ -n "$api_key_param" ]; then
        echo "  ‚úÖ API key stored in SSM Parameter Store"
    else
        echo "  ‚ùå API key not found in SSM Parameter Store"
        sync_issues=$((sync_issues + 1))
    fi
    
    # Check CloudWatch billing alarm
    local billing_alarm=$(aws cloudwatch describe-alarms \
        --alarm-names "Stock-Analyzer-High-Cost" \
        --query 'MetricAlarms[0].AlarmName' \
        --output text 2>/dev/null || echo "")
    
    if [ -n "$billing_alarm" ]; then
        echo "  ‚úÖ Billing alarm configured"
    else
        echo "  ‚ùå Billing alarm not found"
        sync_issues=$((sync_issues + 1))
    fi
    
    echo ""
    echo "üìä Sync Summary:"
    echo "================"
    
    if [ $sync_issues -eq 0 ]; then
        echo "‚úÖ All infrastructure components are synced with production"
        echo "   Your scripts match the deployed infrastructure"
    else
        echo "‚ùå Found $sync_issues sync issues that need attention"
        echo ""
        echo "üîß To fix sync issues:"
        echo "  1. Review the mismatches above"
        echo "  2. Update script configurations if needed"
        echo "  3. Run full deployment: $0"
        echo "  4. Or update specific components individually"
    fi
    
    echo ""
    echo "üí° Recommendations:"
    echo "  - Run this check after any manual AWS console changes"
    echo "  - Verify before making infrastructure updates"
    echo "  - Use as part of your deployment validation process"
    
    return $sync_issues
}

# Function to optimize costs (from optimize_costs.sh)
optimize_costs() {
    echo "üí∞ Optimizing AWS Costs for 7H Stock Analyzer..."
    
    # Optimize Lambda settings
    echo "üîß Optimizing Lambda Functions..."
    local function_name=$(aws lambda list-functions \
        --query "Functions[?contains(FunctionName, 'StockAnalyzerFunction')].FunctionName" \
        --output text 2>/dev/null || echo "")
    
    if [ -n "$function_name" ]; then
        local current_memory=$(aws lambda get-function-configuration \
            --function-name "$function_name" \
            --query 'MemorySize' \
            --output text 2>/dev/null || echo "512")
        
        local current_timeout=$(aws lambda get-function-configuration \
            --function-name "$function_name" \
            --query 'Timeout' \
            --output text 2>/dev/null || echo "180")
        
        echo "    Current: Memory=${current_memory}MB, Timeout=${current_timeout}s"
        
        # Get recent execution metrics
        local avg_duration=$(aws logs filter-log-events \
            --log-group-name "/aws/lambda/$(basename $function_name)" \
            --start-time $(date -d "7 days ago" +%s)000 \
            --end-time $(date +%s)000 \
            --filter-pattern "REPORT" \
            --query 'events[?contains(message, `Duration`)].message | [0]' \
            --output text 2>/dev/null | grep -o 'Duration: [0-9.]* ms' | awk '{print $2}' | sort -n | head -1 || echo "100")
        
        if (( $(echo "$avg_duration < 5000" | bc -l) )); then
            echo "    üí° Recommendation: Reduce memory to 256MB (fast execution)"
        fi
        
        if (( $(echo "$avg_duration < 30000" | bc -l) )); then
            echo "    üí° Recommendation: Reduce timeout to 60s"
        fi
    fi
    
    # Optimize S3 storage
    echo "ü™£ Optimizing S3 Storage..."
    local bucket_name="$S3_BUCKET_NAME_PROD"
    
    if aws s3 ls "s3://$bucket_name" &>/dev/null; then
        local size_bytes=$(aws s3 ls "s3://$bucket_name" --recursive --summarize | grep "Total Size" | awk '{print $3}' || echo "0")
        local size_gb=$(echo "scale=2; $size_bytes / (1024^3)" | bc -l)
        
        echo "    Current size: ${size_gb}GB"
        
        if (( $(echo "$size_gb > 1" | bc -l) )); then
            echo "    üí° Recommendation: Aggressive lifecycle policies"
            echo "      - Delete daily data after 30 days"
            echo "      - Delete charts after 7 days"
        fi
    fi
    
    echo ""
    echo "üí° Cost Optimization Tips:"
    echo "  1. Use AWS Compute Savings Plans for predictable workloads"
    echo "  2. Enable S3 Intelligent-Tiering for unknown access patterns"
    echo "  3. Set up billing alerts to monitor costs"
    echo "  4. Monitor and clean up unused resources"
}

# =============================================================================
# INFRASTRUCTURE MANAGEMENT COMMANDS
# =============================================================================

# Add infrastructure management commands
case "${1:-}" in
    "cleanup-cloudfront")
        echo "üßπ Running CloudFront cleanup..."
        cleanup_old_cloudfront_distributions
        echo ""
        echo "üìã Current distributions:"
        aws cloudfront list-distributions --query 'DistributionList.Items[*].{Id:Id,DomainName:DomainName,Comment:Comment,Status:Status}' --output table
        ;;
    "monitor-costs")
        monitor_costs
        ;;
    "optimize-costs")
        optimize_costs
        ;;
    "sync-check")
        sync_production_infra
        ;;
    "help")
        echo "üîß 7H Stock Analyzer - Infrastructure Management"
        echo "=============================================="
        echo ""
        echo "Usage: $0 [COMMAND]"
        echo ""
        echo "Commands:"
        echo "  (no args)     Full deployment"
        echo "  --quick       Quick Lambda update"
        echo "  cleanup-cloudfront  Clean up old CloudFront distributions"
        echo "  monitor-costs      Monitor AWS costs"
        echo "  optimize-costs     Optimize AWS costs"
        echo "  sync-check         Verify production sync"
        echo "  help               Show this help"
        echo ""
        echo "Examples:"
        echo "  $0                    # Full deployment"
        echo "  $0 --quick           # Quick update"
        echo "  $0 cleanup-cloudfront # Cleanup CloudFront"
        echo "  $0 monitor-costs     # Check costs"
        echo "  $0 optimize-costs    # Optimize costs"
        echo "  $0 sync-check        # Verify production sync"
        ;;
esac

# Clean up old Lambda layer versions (storage optimization)
echo "üßπ Cleaning up old Lambda layer versions..."
LAYER_NAME="StockAnalyzerDependencies"
LATEST_VERSION=$(aws lambda list-layer-versions --layer-name $LAYER_NAME --query 'max(LayerVersions[].Version)' --output text 2>/dev/null || echo "0")

if [ "$LATEST_VERSION" != "0" ] && [ "$LATEST_VERSION" -gt 1 ]; then
    echo "Found $LATEST_VERSION layer versions, cleaning up old versions..."
    
    # Delete all versions except the latest one
    for ((i=1; i<LATEST_VERSION; i++)); do
        echo "Deleting layer version $i..."
        aws lambda delete-layer-version --layer-name $LAYER_NAME --version-number $i 2>/dev/null && echo "‚úÖ Deleted version $i" || echo "‚ùå Failed to delete version $i"
    done
    
    echo "‚úÖ Layer cleanup completed. Kept only version $LATEST_VERSION"
    echo "üí∞ Storage cost reduced by ~90%"
else
    echo "‚úÖ No old layer versions to clean up (latest version: $LATEST_VERSION)"
fi

echo "‚úÖ Deployment cleanup completed"

# Setup weekly reconciliation monitoring
echo ""
echo "üîÑ Setting up weekly reconciliation monitoring..."

# Create S3 prefix for reconciliation data
echo "üìÅ Creating reconciliation data structure..."
aws s3api put-object \
    --bucket "$S3_BUCKET_NAME_PROD" \
    --key "recon/.gitkeep" \
    --content-type "application/octet-stream" \
    --region $AWS_REGION || echo "‚ÑπÔ∏è  Recon directory already exists"

# Test reconciliation endpoint
echo "üß™ Testing reconciliation endpoint..."
API_URL=$(aws cloudformation describe-stacks \
    --stack-name "$STACK_NAME" \
    --query 'Stacks[0].Outputs[?OutputKey==`ApiUrl`].OutputValue' \
    --output text)

if [ -n "$API_URL" ]; then
    echo "üåê API URL: $API_URL"
    
    # Test recon endpoint (will show 0 initially, but confirms it works)
    echo "üìä Testing reconciliation API..."
    RECON_RESPONSE=$(curl -s -w "%{http_code}" "$API_URL/recon/summary" || echo "000")
    
    if [[ "$RECON_RESPONSE" == *"200"* ]]; then
        echo "‚úÖ Reconciliation API endpoint is working"
    else
        echo "‚ö†Ô∏è  Reconciliation API test failed (expected for new deployment)"
    fi
    
    echo ""
    echo "üìã Weekly Reconciliation Details:"
    echo "  üïê Schedule: Every Sunday at 6:00 PM EST (23:00 UTC)"
    echo "  üìä Data: Tracks profit targets vs stop losses"
    echo "  üìà Metrics: Days to target, success rates, performance by type"
    echo "  üîó Endpoint: $API_URL/recon/summary"
    echo "  üóÇÔ∏è  Storage: s3://$S3_BUCKET_NAME_PROD/recon/daily/"
    echo ""
    echo "üéØ To view reconciliation data:"
    echo "  curl -s $API_URL/recon/summary | jq ."
    echo "  curl -s $API_URL/recon/daily/\$(date +%Y-%m-%d) | jq ."
else
    echo "‚ö†Ô∏è  Could not get API URL - reconciliation may need manual testing"
fi

echo ""
echo "‚úÖ Weekly reconciliation setup completed!"

# Verify rate limiting configuration
echo ""
echo "üîí Verifying rate limiting configuration..."

# Get API Gateway ID for rate limiting verification
API_GATEWAY_ID=$(aws apigatewayv2 get-apis \
    --query "Items[?Name=='7h-stock-analyzer'].ApiId" \
    --output text \
    --region $AWS_REGION 2>/dev/null || echo "")

if [ -n "$API_GATEWAY_ID" ] && [ "$API_GATEWAY_ID" != "None" ]; then
    echo "üö¶ API Gateway ID: $API_GATEWAY_ID"
    
    # Get current stage configuration
    echo "üìã Current rate limiting configuration:"
    aws apigatewayv2 get-stage \
        --api-id "$API_GATEWAY_ID" \
        --stage-name "\$default" \
        --region $AWS_REGION \
        --query 'RouteSettings' \
        --output table 2>/dev/null || echo "  ‚ÑπÔ∏è  Rate limiting configured in template"
    
    echo ""
    echo "üéØ Rate limiting limits by endpoint:"
    echo "  GET /recommendations: 20 req/s burst 10"
    echo "  POST /run-now: 10 req/s burst 5"
    echo "  GET /history/{date}: 30 req/s burst 15"
    echo "  GET /history/{date}/enhanced: 10 req/s burst 5"
    echo "  POST /recon/run: 5 req/s burst 2"
    echo "  GET /config: 15 req/s burst 10"
    echo "  POST /config/update: 10 req/s burst 5"
    echo "  Default: 100 req/s burst 20"
    
    echo ""
    echo "üß™ To test rate limiting:"
    echo "  # Test normal operation (should work)"
    echo "  curl -H \"X-API-Key: \$API_KEY\" $API_URL/health"
    echo ""
    echo "  # Test throttling (rapid requests may get 429)"
    echo "  for i in {1..10}; do curl -H \"X-API-Key: \$API_KEY\" $API_URL/health; done"
else
    echo "‚ö†Ô∏è  Could not verify rate limiting - may need manual check"
fi

echo ""
echo "üîí Rate limiting verification completed!"
