#!/bin/bash

# Comprehensive test runner for 7H Stock Analyzer

set -e

echo "ğŸ§ª Running 7H Stock Analyzer Test Suite..."
echo "=========================================="

# Get the directory where this script is located
SCRIPT_DIR="$(cd "$(dirname "${BASH_SOURCE[0]}")" && pwd)"
PROJECT_ROOT="$(dirname "$SCRIPT_DIR")"
BACKEND_DIR="$PROJECT_ROOT/backend"

cd "$BACKEND_DIR"

# Check if virtual environment exists
if [ ! -d "venv" ]; then
    echo "âŒ Virtual environment not found. Creating one..."
    python3 -m venv venv
    source venv/bin/activate
    
    echo "ğŸ“¦ Installing dependencies..."
    pip install -r requirements.txt
else
    echo "âœ… Activating virtual environment..."
    source venv/bin/activate
fi

# Set test environment variables
export PYTHONPATH="${BACKEND_DIR}:${PYTHONPATH}"
export API_KEY="test-api-key-12345"
export REQUIRE_AUTH="true"
export ENVIRONMENT="test"

echo ""
echo "ğŸ”¬ Running Test Categories..."
echo "==========================="

# 1. Recommendation Engine Tests
echo "ğŸ“Š Testing Recommendation Engine..."
python -m pytest tests/test_recommendation_engine.py -v --tb=short --cov=app.modules.recommendation_engine --cov-report=term-missing

# 2. Signal Engine Tests
echo "ğŸ“ˆ Testing Signal Engine..."
python -m pytest tests/test_signal_engine.py -v --tb=short --cov=app.modules.signal_engine --cov-report=term-missing

# 3. Reconciliation Service Tests
echo "ğŸ”„ Testing Reconciliation Service..."
python -m pytest tests/test_reconciliation_service.py -v --tb=short --cov=app.services.recon_service --cov-report=term-missing

# 4. API Endpoint Tests
echo "ğŸŒ Testing API Endpoints..."
python -m pytest tests/test_api_endpoints.py -v --tb=short --cov=app.main --cov-report=term-missing

echo ""
echo "ğŸ¯ Running Integration Tests..."
echo "=============================="

# 5. Integration Tests (if any)
echo "ğŸ”— Testing Component Integration..."
python -m pytest tests/ -k "integration" -v --tb=short || echo "â„¹ï¸ No integration tests found"

echo ""
echo "ğŸ“Š Test Summary & Coverage Report"
echo "==============================="

# Generate combined coverage report
python -m pytest tests/ --cov=app --cov-report=term --cov-report=html:htmlcov --cov-report=xml --tb=short

echo ""
echo "âœ… Test Suite Completed!"
echo "======================"
echo ""
echo "ğŸ“‹ Test Results Summary:"
echo "  - Recommendation Engine: Target prices, risk/reward ratios, scoring logic"
echo "  - Signal Engine: Technical indicator signals, weight calculations"
echo "  - Reconciliation Service: Performance tracking, profit/stop loss calculations"
echo "  - API Endpoints: Authentication, response structures, error handling"
echo ""
echo "ğŸ“ˆ Coverage Report Generated:"
echo "  - Terminal: Displayed above"
echo "  - HTML: Open htmlcov/index.html in browser"
echo "  - XML: For CI/CD integration"
echo ""
echo "ğŸ” To run specific test categories:"
echo "  python -m pytest tests/test_recommendation_engine.py -v"
echo "  python -m pytest tests/test_signal_engine.py -v"
echo "  python -m pytest tests/test_reconciliation_service.py -v"
echo "  python -m pytest tests/test_api_endpoints.py -v"
echo ""
echo "ğŸš¨ To run tests with specific focus:"
echo "  python -m pytest tests/ -k 'target_price' -v  # Target price tests"
echo "  python -m pytest tests/ -k 'risk_reward' -v     # Risk/reward tests"
echo "  python -m pytest tests/ -k 'reconciliation' -v # Reconciliation tests"
echo ""
echo "ğŸ“ To run tests with detailed output:"
echo "  python -m pytest tests/ -v -s --tb=long"
echo ""
echo "ğŸ¯ Test integrity ensures:"
echo "  âœ… Target prices are calculated correctly"
echo "  âœ… Risk/reward ratios are always favorable"
echo "  âœ… Signal generation is consistent and accurate"
echo "  âœ… Reconciliation tracking is precise"
echo "  âœ… API endpoints are secure and reliable"
echo "  âœ… Error handling is robust"
echo "  âœ… Data structures are consistent"
